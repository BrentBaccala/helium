# -*- mode: python -*-
#
# Python code to search for solutions of Hydrogen and Helium
# non-relativistic time-invariant Schrodinger equation
#
# INTERACTIVE USAGE:
#
# load('helium.sage')
# prep_hydrogen(5)
# init()
# ideal(eqns_RQQ).minimal_associate_primes()
#
# This will produce a solution to the hydrogen atom using ansatz 5.
# You can also prep_helium(), and supply an ansatz number as argument,
# as in prep_helium(-7).
#
# Negative ansatzen use a spherically symmetric Hamiltonian that
# reduces the dimension of the problem and lets us use the faster
# FLINT implementation because there are no roots in the Hamiltonian
# and FLINT doesn't have a Groebner basis implementation, which is
# required to handle roots.
#
# "Homogenization" (not a very good term) is used to force selected
# polynomials to be non-zero by forcing their coefficients to be 1,
# one at a time.  Different values of the 'homogenize' argument
# (starting at 0) force different coefficients to be 1, and an
# exception is thrown once all of the homogenization possibilities
# have been exhausted.  Specifying homogenize=-1 runs through
# all possible homogenizations (usually what you want).
#
# Homogenization can also be done when the trial solution is
# constructed (this is the 'homogenize' argument to the
# trial_polynomial function), which produces systems with fewer free
# coefficients, but a new system has to be constructed for every
# homogenization possibility, so I don't do it this way, and only plan
# to develop this option if computational complexity becomes an issue.
#
# CONCEPT:
#
# We have a differential equation that we're trying to solve and a
# trial solution with lots of free parameters that we try to adjust
# to get a solution.
#
# ALGORITHM:
#
# We start with a trial solution with free coefficients (coeff_vars)
# that we hope will yield an exact solution if they are set to the
# correct real numbers.  We don't try to reduce the complexity of this
# system to the point where we have single isolated solutions, so we
# expect our solutions to be higher-dimensional algebraic varieties.
#
# We plug the trial solution into the differential equation that we're
# trying to solve, expand it out, and collect coefficients of like
# terms.  This gives us a set of polynomial equations in the
# coefficients that define an algebraic variety in the space generated
# by the coefficient variables.  We find the minimal associated
# primes of the ideal generated by the polynomials, which gives
# us a decomposition of the solution space into irreducible varieties.
#
# by Brent Baccala
#
# first version - August 2019
# latest version - December 2024
#
# no rights reserved; you may freely copy, modify, or distribute this
# program
#
# TODO list:
# - check collected coefficient polynomials to see if they factor

import itertools
from itertools import *

# import functools for functools.lru_cache
import functools

import subprocess

import threading

import pickle
import io

import os
import psutil
import datetime

import typing

import hashlib
import uuid

import traceback

try:
    from clint.textui.progress import Bar
    # like Bar, but don't display ProgressBar at all if the whole event takes less than a second
    class ProgressBar(Bar):
        def __init__(self, label, expected_size):
            self.timer = threading.Timer(float(1.0), lambda: self.show(-1))
            self.timer.start()
            super().__init__(label=label, expected_size=expected_size, hide=True)
        def show(self, i):
            if i == -1:
                self.hide = False
                super().show(self.last_progress)
            else:
                super().show(i)
        def done(self):
            if self.timer:
                self.timer.cancel()
            else:
                super().done()
except ModuleNotFoundError:
    print("clint package not available; no progress bars will be displayed")
    class ProgressBar:
        def __init__(self, label, expected_size):
            pass
        def show(self, i):
            pass
        def done(self):
            pass

postgres_connection_parameters = {
    'host':     '192.168.2.201',
    'user':     'baccala',
}

try:
    import psycopg2
except ModuleNotFoundError:
    print("psycopg2 package not available; no SQL database support")

def postgres_connect():
    try:
        global conn
        conn = psycopg2.connect(**postgres_connection_parameters)
    except psycopg2.OperationalError as ex:
        print('SQL OperationalError during connection attempt; no SQL database support')
    except NameError as ex:
        if ex.name == 'psycopg2':
            # if we couldn't load psycopg2, we already printed a warning
            pass
        else:
            raise

# from python docs
def flatten(listOfLists):
    "Flatten one level of nesting"
    return chain.from_iterable(listOfLists)

# from python docs
def powerset(iterable):
    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

def trial_polynomial(base, coordinates, roots, degree, homogenize=None, constant=True, first_index=0):
    """trial_polynomial(base, coordinates, roots, degree, homogenize=None, constant=True)
    Form a trial polynomial in the Symbolic Ring

    base is a string to which we append numbers to get our coefficient names; i.e, 'a' -> (a0,a1,a2,...)
    coordinates is a tuple of symbolic expressions (currently all symbols; i.e, x1.is_symbol() == True)
    roots is a tuple of symbolic expressions for our roots (currently all powers; i.e, r.operator() == pow) (and all square roots)
    degree is maximum degree of the trial polynomial
    constant=None is optional and drops the constant term (essentially mindeg=1 instead of mindeg=0)
    homogenize=N is unused right now and is intended as a future performance optimization

    The difference between 'coordinates' and 'roots' is that we never use higher powers of roots (>= 2) no matter
    what 'degree' is.  This assumes that the roots are square roots, of course, a current limitation of the code.
    """

    if not constant:
        mindegree = 1
    else:
        mindegree = 0
    terms = []
    for deg in range(mindegree, degree+1):
        terms += list(map(mul, (x for x in combinations_with_replacement(coordinates + roots, deg) if all(x.count(r) < 2 for r in roots))))

    coefficients = [var(base+str(c)) for c in range(first_index, first_index + len(terms))]
    poly_coefficients = list(coefficients)
    if homogenize != None:
        # homogenize: use 1 as the coefficient of the homogenize'th term
        #   and set all previous terms to 0.
        # The idea is to prevent a polynomial from being zero by running successive
        #   calculations running through all the terms of the polynomial, forcing them to be 1.
        if homogenize >= 0:
            homogenize_coefficient = homogenize % len(coefficients)
            if homogenize_coefficient > 0:
                poly_coefficients[0:homogenize_coefficient] = [0] * (homogenize_coefficient)
            poly_coefficients[homogenize_coefficient]= 1
            del coefficients[0:homogenize_coefficient+1]
        else:
            # if homogenize is negative, we set the coefficient of that term equal to 1,
            # but don't set all previous terms to 0.  I use this in ansatz 16.31
            homogenize_coefficient = -homogenize
            poly_coefficients[homogenize_coefficient]= 1
            del coefficients[homogenize_coefficient]

    poly = sum([poly_coefficients[c]*v for c,v in enumerate(terms)])
    return (tuple(coefficients), poly)

# Energy constant in Schroedinger's equations
var('E')

def Del(Psi,vars):
    return sum([diff(Psi,v,2) for v in vars])

# Create an operator (DD) that takes derivatives of symbolic functions
# w.r.t. their arguments, i.e, `DD[0](Phi)(A)` is the derivative of
# Phi w.r.t. its 0-th argument, `A`.
#
# from https://groups.google.com/g/sage-devel/c/xBHw11qUARg/m/0eqj3eUFsFkJ
# referenced from https://trac.sagemath.org/ticket/17445

from sage.symbolic.operators import FDerivativeOperator
class Doperator:
  def __init__(self,vars=None):
    self.vars= [] if vars is None else vars

  def __call__(self,f):
    return FDerivativeOperator(f,self.vars)

  def __getitem__(self,i):
    if isinstance(i,tuple):
       newvars=self.vars+list(i)
    else:
       newvars=self.vars+[i]
    return Doperator(newvars)

DD=Doperator()

def finish_prep(ansatz):
    global eq, H, coeff_vars, ODE_vars, coordinates, roots
    global A,B,C,D,F,G,M,N,V
    global homogenize_groups
    global alg_exts
    global gamma

    (Avars, A) = trial_polynomial('a', coordinates, roots, 1)
    (Bvars, B) = trial_polynomial('b', coordinates, roots, 1)
    (Cvars, C) = trial_polynomial('c', coordinates, roots, 1)
    (Dvars, D) = trial_polynomial('d', coordinates, roots, 1)
    (Fvars, F) = trial_polynomial('f', coordinates, roots, 1)
    (Gvars, G) = trial_polynomial('g', coordinates, roots, 1)

    SR_function = sage.symbolic.function_factory.function

    alg_exts = tuple()

    if ansatz == 1:
        # A linear polynomial times the exponential of a linear polynomial
        # Phi is an exponential of a linear polynomial
        # Phi = e^B, so diff(Phi,B) = Phi and diff(Phi,v) = diff(B,v)*Phi
        # A is a linear polynomial; the solution is A times Phi.
        # Homogenization forces A to be non-zero.
        #
        # An earlier verion of this ansatz was used extensively for testing Hydrogen
        Phi = SR_function('Phi')
        (Avars, A) = trial_polynomial('a', coordinates, roots, 1)
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1)
        Psi = A * Phi(B)
        # subs is a list of dictionaries defining substitutions.  They are executed in order.
        subs = [{DD[0](Phi)(B) : Phi(B), DD[0,0](Phi)(B) : Phi(B)},
                {Phi(B) : SR.var('Phi')}
        ]
        homogenize_groups = (Avars, Bvars)
        coeff_vars = (E,) + Avars + Bvars
        ODE_vars = ('Phi', )

    elif ansatz == 2:
        # A linear polynomial times the logarithm of a linear polynomial
        # Xi is a logarithm; Xi = ln C, so diff(Xi,C) = 1/C and diff(Xi,v) = diff(C,v)/C
        # A is a linear polynomial; the solution is A times Xi.
        # Homogenization forces A and C to be non-zero
        #
        # I've used this ansatz very little.
        Xi = SR_function('Xi')
        Psi = A * Xi(C)
        subs = [{DD[0](Xi)(C) : 1/C, DD[0,0](Xi)(C) : -1/C^2},
                {Xi(C) : SR.var('Xi')}
        ]
        homogenize_groups = (Avars, Cvars)
        coeff_vars = (E,) + Avars + Cvars
        ODE_vars = ('Xi', )

    elif ansatz == 3:
        # Chi is a weird second-order mess: C d^2 Chi/dB^2 - D dChi/dB - F Chi - G = 0
        # A is a linear polynomial; the solution is A times Chi.
        #
        # I declared Chi to be a function of B, but in retrospect, it's also a
        # function of C, D, F, and G, none of which are (necessarily) functions of B
        #
        # Homogenization forces A, B and C to be non-zero, and B is non-constant.
        #
        # I've used this ansatz very little; ansatz 4 is closely related
        Chi = SR_function('Chi')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1, constant=None)
        Psi = A*Chi(B)

        homogenize_groups = (Avars, Bvars, Cvars)
        coeff_vars = (E,) + Avars + Bvars + Cvars + Dvars + Fvars + Gvars

        subs = [{DD[0,0](Chi)(B) : (D/C * DD[0](Chi)(B) + F/C * Chi(B)) + G/C},
                {Chi(B) : SR.var('Chi'), DD[0](Chi)(B) : SR.var('DChi')}
        ]
        ODE_vars = ('Chi', 'DChi')

    elif ansatz == 4:
        # Like ansatz 3, but without the polynomial A as a factor, and thus simplier
        #
        # Homogenization forces B and C to be non-zero, and B is non-constant.
        #
        # This ansatz is fairly well explored, but in an earlier version of the code
        # (pre-edbaa8 and pre-e74ded) whose ring and class structures aren't compatible.
        Chi = SR_function('Chi')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1, constant=None)
        Psi = Chi(B)

        homogenize_groups = (Bvars, Cvars)
        coeff_vars = (E,) + Bvars + Cvars + Dvars + Fvars + Gvars

        subs = [{DD[0,0](Chi)(B) : (D/C * DD[0](Chi)(B) + F/C * Chi(B)) + G/C},
                {Chi(B) : SR.var('Chi'), DD[0](Chi)(B) : SR.var('DChi')}
        ]
        ODE_vars = ('Chi', 'DChi')

    elif ansatz == 5 or ansatz == 5.01:
        # A second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 + M(V) dZeta/dV + N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V, which is itself a linear polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant
        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots, 1, constant=None, first_index=1)
        Psi = Zeta(V)
        if ansatz == 5.01:
            # use 'homogenize' to set the coeffient of v in the ODE's second order coefficient to 1
            (Avars, A) = trial_polynomial('a', [V], [], 1, homogenize=-1)
        else:
            (Avars, A) = trial_polynomial('a', [V], [], 1)
        (Bvars, B) = trial_polynomial('b', [V], [], 1)
        (Cvars, C) = trial_polynomial('c', [V], [], 1)

        homogenize_groups = (Avars, Vvars)

        coeff_vars = (E,) + Vvars + Avars + Bvars + Cvars

        subs = [{DD[0,0](Zeta)(V) : -(B * DD[0](Zeta)(V) + C * Zeta(V)) / A},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 5.1:
        # A second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V, which is a quadratic polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant
        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots, 2, constant=None)
        Psi = Zeta(V)
        (Dvars, D) = trial_polynomial('d', [V], [], 1)
        (Mvars, M) = trial_polynomial('m', [V], [], 1)
        (Nvars, N) = trial_polynomial('n', [V], [], 1)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 5.2:
        # A second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are quadratic polynomials in V, which is a linear polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant
        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots, 1, constant=None)
        Psi = Zeta(V)
        (Dvars, D) = trial_polynomial('d', [V], [], 2)
        (Mvars, M) = trial_polynomial('m', [V], [], 2)
        (Nvars, N) = trial_polynomial('n', [V], [], 2)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 5.3:
        # A second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are quadratic polynomials in V, which is also a quadratic polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant
        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots, 2, constant=None)
        Psi = Zeta(V)
        (Dvars, D) = trial_polynomial('d', [V], [], 2)
        (Mvars, M) = trial_polynomial('m', [V], [], 2)
        (Nvars, N) = trial_polynomial('n', [V], [], 2)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 6:
        # A second-order homogeneous ODE: D(B/C) d^2 Zeta/d(B/C)^2 - M(B/C) dZeta/d(B/C) - N(B/C) Zeta = 0
        # where D(B/C), M(B/C), and N(B/C) are linear polynomials in B/C, a first-degree rational function
        Zeta = SR_function('Zeta')
        Psi = Zeta(B/C)
        (Dvars, D) = trial_polynomial('d', [B/C], [], 1)
        (Mvars, M) = trial_polynomial('m', [B/C], [], 1)
        (Nvars, N) = trial_polynomial('n', [B/C], [], 1)

        coeff_vars = (E,) + Bvars + Cvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(B/C) : (M * DD[0](Zeta)(B/C) + N * Zeta(B/C)) / D},
                {Zeta(B/C) : SR.var('Zeta'), DD[0](Zeta)(B/C) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 7:
        # A second-order homogeneous ODE: D(B/C) d^2 Zeta/d(B/C)^2 - M(B/C) dZeta/d(B/C) - N(B/C) Zeta = 0
        # where D(B/C), M(B/C), and N(B/C) are second-degree polynomials in B/C, a second-degree rational function
        Zeta = SR_function('Zeta')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 2, homogenize=0)
        (Cvars, C) = trial_polynomial('c', coordinates, roots, 2, homogenize=1)
        Psi = Zeta(B/C)
        (Dvars, D) = trial_polynomial('d', [B/C], [], 2, homogenize=0)
        (Mvars, M) = trial_polynomial('m', [B/C], [], 2)
        (Nvars, N) = trial_polynomial('n', [B/C], [], 2)

        coeff_vars = (E,) + Bvars + Cvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(B/C) : (M * DD[0](Zeta)(B/C) + N * Zeta(B/C)) / D},
                {Zeta(B/C) : SR.var('Zeta'), DD[0](Zeta)(B/C) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 8:
        # A first-order homogeneous ODE: M(B) dZeta/dB - N(B) Zeta = 0
        # where M(B) and N(B) are linear polynomials in B, which is itself a linear polynomial
        # B can not be constant; neither B or M can be zero (homogenization)
        #
        # Logically it's a step backwards from ansatz 5, but I want to see it work.

        Zeta = SR_function('Zeta')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1, constant=None)
        Psi = Zeta(B)
        (Mvars, M) = trial_polynomial('m', [B], [], 1)
        (Nvars, N) = trial_polynomial('n', [B], [], 1)

        homogenize_groups = (Mvars, Bvars)
        coeff_vars = (E,) + Bvars + Mvars + Nvars

        # A limitation of the program is that I have to manually calculate DD[0,0](Zeta)(B) here
        #  DD[0,0](Zeta)(B)  = d^2 Zeta / dB^2 = d/dB (N(B) * Zeta(B) / M(B))
        #     = (dN/dB * Zeta(B) * M(B) + N(B) * DD[0](Zeta)(B) * M(B) - N(B) * Zeta(B) * dM/dB ) / M^2(B)
        #     = (n1 * Zeta(B) * M(B) + N(B) * DD[0](Zeta)(B) * M(B) - N(B) * Zeta(B) * m1 ) / M^2(B)
        #
        # Can't write diff(M,B) because B is a polynomial and diff only accepts a symbol as its second argument.
        # Yet we know that M = m1*B + m0, so diff(M,B)=m1
        m1 = Mvars[1]
        n1 = Nvars[1]
        subs = [{DD[0](Zeta)(B) : (N * Zeta(B)) / M,
                 DD[0,0](Zeta)(B) : (n1 * Zeta(B) * M + N * N * Zeta(B) - N * Zeta(B) * m1 ) / (M*M) },
                {Zeta(B) : SR.var('Zeta')}
        ]
        ODE_vars = ('Zeta', )

    elif ansatz == 9:
        # A first-order homogeneous ODE: dZeta/dB - n0 Zeta = 0
        # where n0 is a constant and B is a linear polynomial
        #
        # Logically it's a further step backwards from ansatz 8, but ansatz 8 has too many free variables
        # for scipy.optimize.root to work on 1-dim hydrogen if we use homogenization
        Zeta = SR_function('Zeta')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1, constant=None)
        Psi = Zeta(B)
        (Nvars, N) = trial_polynomial('n', [B], [], 0)

        homogenize_groups = (Bvars, )
        coeff_vars = (E,) + Bvars + Nvars

        # A limitation of the program is that I have to manually calculate DD[0,0](Zeta)(B) here
        #  DD[0](Zeta)(B)  = n0 Zeta(B)
        #  DD[0,0](Zeta)(B)  = n0^2 Zeta(B)

        n0 = Nvars[0]
        subs = [{DD[0](Zeta)(B) : n0 * Zeta(B),
                 DD[0,0](Zeta)(B) : n0^2 * Zeta(B)},
                {Zeta(B) : SR.var('Zeta')}
        ]
        ODE_vars = ('Zeta', )

    elif ansatz == 10:
        # A second-order homogeneous ODE: D(B) d^2 Zeta/dB^2 - M(B) dZeta/dB - N(B) Zeta = 0
        # where D(B), M(B), and N(B) are quadratic polynomials in B, which is itself a quadratic polynomial
        #
        # Homogenization forces B and D to be non-zero; B is also forced to be non-constant
        Zeta = SR_function('Zeta')
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 2, constant=None)
        Psi = Zeta(B)
        (Dvars, D) = trial_polynomial('d', [B], [], 2)
        (Mvars, M) = trial_polynomial('m', [B], [], 2)
        (Nvars, N) = trial_polynomial('n', [B], [], 2)

        homogenize_groups = (Dvars, Bvars)

        coeff_vars = (E,) + Bvars + Dvars + Mvars + Nvars

        subs = [{DD[0,0](Zeta)(B) : (M * DD[0](Zeta)(B) + N * Zeta(B)) / D},
                {Zeta(B) : SR.var('Zeta'), DD[0](Zeta)(B) : SR.var('DZeta')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

    elif ansatz == 11:
        # A second-degree algebraic extension (linear coeffs) followed by
        # a second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V, which is itself a linear polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant

        (Avars, A) = trial_polynomial('a', coordinates, roots, 1)
        (Bvars, B) = trial_polynomial('b', coordinates, roots, 1)
        (Cvars, C) = trial_polynomial('c', coordinates, roots, 1)
        def deriv(self, *args,**kwds):
            #print("{} {} {}".format(self, args, kwds))
            wrt = args[kwds['diff_param']]
            return -(diff(A, wrt)*self(*coordinates)^2+diff(B,wrt)*self(*coordinates)+diff(C,wrt)/(2*A*self(*coordinates)+B))
        # anything that isn't constant w.r.t. coordinates is an SR_function
        gamma = SR_function('g', nargs=len(coordinates), derivative_func=deriv)

        # We can construct derivatives like this, too:
        # sage: DD[0](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), x1)
        # sage: DD[1](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), y1)
        # sage: DD[1,1](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), y1, y1)

        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots + (gamma(*coordinates),), 1, constant=None)
        Psi = Zeta(V)
        (Dvars, D) = trial_polynomial('d', [V], [], 1)
        (Mvars, M) = trial_polynomial('m', [V], [], 1)
        (Nvars, N) = trial_polynomial('n', [V], [], 1)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars + Avars + Bvars + Cvars
        print(coeff_vars)

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')},
                {gamma(*coordinates) : SR.var('g')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

        alg_exts = (('g', A*gamma(*coordinates)^2 + B*gamma(*coordinates) + C, subs[2]),)

    elif int(ansatz) == 12:
        # A second-degree homogenous ODE (linear coeffs) followed by another
        # second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V, which is itself a linear polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant

        # trial_polynomial returns a tuple: the coefficient variables used, and the polynomial itself

        if ansatz == 12:
            maxdeg_v = 1
            maxdeg_u = 1
            maxdeg_ode_v = 1
            maxdeg_ode_u = 1
        elif ansatz == 12.1:
            maxdeg_v = 2
            maxdeg_u = 1
            maxdeg_ode_v = 1
            maxdeg_ode_u = 1
        elif ansatz == 12.2:
            maxdeg_v = 1
            maxdeg_u = 2
            maxdeg_ode_v = 1
            maxdeg_ode_u = 1
        elif ansatz == 12.3:
            maxdeg_v = 1
            maxdeg_u = 1
            maxdeg_ode_v = 2
            maxdeg_ode_u = 1
        elif ansatz == 12.4:
            maxdeg_v = 1
            maxdeg_u = 1
            maxdeg_ode_v = 1
            maxdeg_ode_u = 2

        Theta = SR_function('Theta')
        (Uvars, U) = trial_polynomial('u', coordinates, roots, maxdeg_u, constant=None)
        (Avars, A) = trial_polynomial('a', [U], [], maxdeg_ode_u)
        (Bvars, B) = trial_polynomial('b', [U], [], maxdeg_ode_u)
        (Cvars, C) = trial_polynomial('c', [U], [], maxdeg_ode_u)

        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates + (Theta(U),), roots, maxdeg_v, constant=None)

        (Dvars, D) = trial_polynomial('d', [V], [], maxdeg_ode_v)
        (Mvars, M) = trial_polynomial('m', [V], [], maxdeg_ode_v)
        (Nvars, N) = trial_polynomial('n', [V], [], maxdeg_ode_v)

        # Psi is the solution to the PDE
        Psi = Zeta(V)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Uvars + Avars + Bvars + Cvars + Vvars + Dvars + Mvars + Nvars
        print(coeff_vars)

        # Make sure Zeta(V)->SR(Zeta) comes before Theta(U)->SR(Theta) because
        # Zeta(V) will have Theta(U) in its arguments and the Theta(U) sub screws up that match
        subs = [{DD[0,0](Theta)(U) : (B * DD[0](Theta)(U) + C * Theta(U)) / A},
                {DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')},
                {Theta(U) : SR.var('Theta'), DD[0](Theta)(U) : SR.var('DTheta')}
        ]

        # It does need a list of the additional variables for when it builds the polynomial ring
        # Probably it could just infer this information from the variables present in the equation
        ODE_vars = ('Theta', 'DTheta', 'Zeta', 'DZeta')

    elif int(ansatz) == 13:
        # A second-degree algebraic extension (linear coeffs) used as the coefficient ring
        # in a second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V (a linear polynomial) and gamma.
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant

        if ansatz == 13:
            maxdeg_v = 1
            maxdeg_alg = 1
            maxdeg_ode = 1
        elif ansatz == 13.1:
            maxdeg_v = 2
            maxdeg_ode = 1
            maxdeg_alg = 1
        elif ansatz == 13.2:
            maxdeg_v = 1
            maxdeg_ode = 2
            maxdeg_alg = 1
        elif ansatz == 13.3:
            maxdeg_v = 1
            maxdeg_ode = 1
            maxdeg_alg = 2
        elif ansatz == 13.4:
            maxdeg_v = 2
            maxdeg_ode = 2
            maxdeg_alg = 1
        elif ansatz == 13.5:
            maxdeg_v = 2
            maxdeg_ode = 1
            maxdeg_alg = 2
        elif ansatz == 13.5:
            maxdeg_v = 1
            maxdeg_ode = 2
            maxdeg_alg = 2
        elif ansatz == 13.6:
            maxdeg_v = 2
            maxdeg_ode = 2
            maxdeg_alg = 2

        Zeta = SR_function('Zeta')
        (Vvars, V) = trial_polynomial('v', coordinates, roots, maxdeg_v, constant=None)

        (Avars, A) = trial_polynomial('a', [V], [], maxdeg_alg)
        (Bvars, B) = trial_polynomial('b', [V], [], maxdeg_alg)
        (Cvars, C) = trial_polynomial('c', [V], [], maxdeg_alg)
        def deriv(self, *args,**kwds):
            #print("{} {} {}".format(self, args, kwds))
            return -(diff(A, V)*self(*coordinates)^2+diff(B,V)*self(*coordinates)+diff(C,V)/(2*A*self(*coordinates)+B))
        # anything that isn't constant w.r.t. coordinates is an SR_function
        gamma = SR_function('g', nargs=1, derivative_func=deriv)

        Psi = Zeta(V)
        (Dvars, D) = trial_polynomial('d', [V], [gamma(V)], maxdeg_ode)
        (Mvars, M) = trial_polynomial('m', [V], [gamma(V)], maxdeg_ode)
        (Nvars, N) = trial_polynomial('n', [V], [gamma(V)], maxdeg_ode)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars + Avars + Bvars + Cvars
        print(coeff_vars)

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')},
                {gamma(V) : SR.var('g')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

        #alg_exts = (('g', A*gamma(V)^2 + B*gamma(V) + C, post2_subs),)
        alg_exts = (('g', A*SR.var('g')^2 + B*SR.var('g') + C, subs[2]),)

    elif int(ansatz) == 16:
        # A second-degree algebraic extension (root of a linear polynomial) followed by
        # a second-order homogeneous ODE: D(V) d^2 Zeta/dV^2 - M(V) dZeta/dV - N(V) Zeta = 0
        # where D(V), M(V), and N(V) are linear polynomials in V, which is itself a linear polynomial
        #
        # Homogenization forces V and D to be non-zero; V is also forced to be non-constant

        if ansatz == 16:
            maxdeg_v = 1
            maxdeg_alg = 1
            maxdeg_ode = 1
        elif ansatz == 16.1:
            maxdeg_v = 2
            maxdeg_ode = 1
            maxdeg_alg = 1
        elif ansatz == 16.2:
            maxdeg_v = 1
            maxdeg_ode = 2
            maxdeg_alg = 1
        elif ansatz == 16.3 or ansatz == 16.31:
            maxdeg_v = 1
            maxdeg_ode = 1
            maxdeg_alg = 2
        elif ansatz == 16.4:
            maxdeg_v = 2
            maxdeg_ode = 2
            maxdeg_alg = 1
        elif ansatz == 16.5:
            maxdeg_v = 2
            maxdeg_ode = 1
            maxdeg_alg = 2
        elif ansatz == 16.5:
            maxdeg_v = 1
            maxdeg_ode = 2
            maxdeg_alg = 2
        elif ansatz == 16.6 or ansatz == 16.61:
            maxdeg_v = 2
            maxdeg_ode = 2
            maxdeg_alg = 2

        (Avars, A) = trial_polynomial('a', coordinates, roots, maxdeg_alg)
        def deriv(self, *args,**kwds):
            wrt = args[kwds['diff_param']]
            return diff(A, wrt)/(2*A*self(*coordinates))
        # anything that isn't constant w.r.t. coordinates is an SR_function
        gamma = SR_function('g', nargs=len(coordinates), derivative_func=deriv)

        # We can construct derivatives like this, too:
        # sage: DD[0](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), x1)
        # sage: DD[1](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), y1)
        # sage: DD[1,1](gamma)(x1,y1,z1)
        # diff(g(x1, y1, z1), y1, y1)

        Zeta = SR_function('Zeta')
        if ansatz == 16.31 or ansatz == 16.61:
            # use 'homogenize' to set the coefficient of gamma to 1
            (Vvars, V) = trial_polynomial('v', coordinates, (gamma(*coordinates),) + roots, maxdeg_v, constant=None, homogenize=0)
        else:
            (Vvars, V) = trial_polynomial('v', coordinates, roots + (gamma(*coordinates),), maxdeg_v, constant=None)
        Psi = Zeta(V)
        if ansatz == 16.31 or ansatz == 16.61:
            # use 'homogenize' to set the coeffient of v in the ODE's second order coefficient to 1
            (Dvars, D) = trial_polynomial('d', [V], [], maxdeg_ode, homogenize=-1)
        else:
            (Dvars, D) = trial_polynomial('d', [V], [], maxdeg_ode)
        (Mvars, M) = trial_polynomial('m', [V], [], maxdeg_ode)
        (Nvars, N) = trial_polynomial('n', [V], [], maxdeg_ode)

        homogenize_groups = (Dvars, Vvars)

        coeff_vars = (E,) + Vvars + Dvars + Mvars + Nvars + Avars
        print(coeff_vars)

        subs = [{DD[0,0](Zeta)(V) : (M * DD[0](Zeta)(V) + N * Zeta(V)) / D},
                {Zeta(V) : SR.var('Zeta'), DD[0](Zeta)(V) : SR.var('DZeta')},
                {gamma(*coordinates) : SR.var('g')}
        ]
        ODE_vars = ('Zeta', 'DZeta')

        # alg_exts is a list of tuples
        # each tuple is (name, minimal polynomial, substitution)
        # minimal polynomial has its roots converted to rs, then subsitution is applied, then append to ideal to mod out by
        alg_exts = (('g', gamma(*coordinates)^2 - A, subs[2]),)

    else:
        raise 'Bad ansatz'

    eq = H(Psi) - E*Psi

    for sub in subs:
        eq = eq.subs(sub)

    # reduce coeff_vars to those which actually appear in the equation
    # let's not do this, in case we've got algebraic extension elements (like ansatz 11)
    # coeff_vars = tuple(sorted(set(eq.free_variables()).intersection(coeff_vars), key=lambda x:str(x)))

    # I used to do this in convert_eq_a(), but that function can be slow, and this is pretty quick,
    # so let's put it in the "prep()" step instead of the "init()" step
    create_polynomial_rings(alg_exts)
    create_eq_a()

def prep_hydrogen(ansatz=1):
    global H, coordinates, roots
    global r

    if ansatz < 0:

        var('r')
        coordinates = (r,)
        roots = tuple()

        def H(Psi):
            return - 1/2 * (1/r^2 * diff(r^2 * diff(Psi,r), r)) - (1/r)*Psi

    else:
        var('x,y,z')
        coordinates = (x,y,z)

        r = sqrt(x^2+y^2+z^2)
        roots = (r,)

        def H(Psi):
            return - 1/2 * Del(Psi,[x,y,z]) - (1/r)*Psi

    postgres_connection_parameters['database'] = 'hydrogen-' + str(abs(ansatz))
    postgres_connect()

    finish_prep(ansatz=abs(ansatz))

def prep_helium(ansatz=6):
    global H, coordinates, roots

    if ansatz < 0:
        # According to Nakatsuji, we can write the helium Hamiltonian
        # for S states (no angular momentum) in a r1/r2/r12 coordinate system.
        #
        # That's what we do for a negative ansatz

        var('R1,R2,R12')
        coordinates = (R1,R2,R12)
        roots = tuple()

        # eq (5) in Nakashima and Nakatusji, Solving the Schrodinger equation for helium...
        # THE JOURNAL OF CHEMICAL PHYSICS 127, 224104 2007
        def H(Psi):
            return - 1/2 *sum(diff(Psi, Ri, 2) + 2/Ri*diff(Psi,Ri) for Ri in [R1,R2])  \
                   - (diff(Psi, R12, 2) + 2/R12*diff(Psi,R12))                          \
                   - (R1^2 + R12^2 - R2^2)/(2*R1*R12) * diff(diff(Psi,R12),R1)         \
                   - (R2^2 + R12^2 - R1^2)/(2*R2*R12) * diff(diff(Psi,R12),R2)         \
                   - sum(2/Ri for Ri in [R1,R2])*Psi + 1/R12*Psi

    else:

        var('x1,y1,z1,x2,y2,z2')

        global r1, r2, r12
        r1 = sqrt(x1^2+y1^2+z1^2)
        r2 = sqrt(x2^2+y2^2+z2^2)
        r12 = sqrt((x2-x1)^2 + (y2-y1)^2 + (z2-z1)^2)

        coordinates = (x1,y1,z1, x2,y2,z2)
        roots = (r1,r2,r12)

        def H(Psi):
            return - 1/2 * Del(Psi,[x1,y1,z1]) - 1/2 * Del(Psi,[x2,y2,z2]) - (2/r1)*Psi - (2/r2)*Psi + (1/r12)*Psi

    postgres_connection_parameters['database'] = 'helium-' + str(round(abs(ansatz), 1))
    postgres_connect()

    finish_prep(ansatz=abs(ansatz))


# Now we want to replace all of the sqrt(...) factors with 'r',
# and we use a clever Python trick to build a dictionary
# that maps expressions to variable names.

def varName(var):
    for name,value in globals().items():
        if id(var) == id(value):
            return name
    return None

def mk_maps(roots):
    return {v.operands()[0] : SR.var(varName(v)) for v in roots}

# convert all (x^2+y^2+z^2)^(n/2) expressions to r^n
# What if we have multiple x^2+y^2+z^2 expressions in a single power?
def roots_to_rs(expr):
    if isinstance(expr, Expression) and expr.operator():
       if expr.operator() == operator.pow and bool(expr.operands()[0] in maps):
           return maps[expr.operands()[0]]^(expr.operands()[1] * 2)
       else:
           return expr.operator()(*map(roots_to_rs, expr.operands()))
    else:
       return expr

def create_eq_a():
    # first, build the dictionary that maps expressions like (x1^2+y1^2+z1^2) to variables like r1
    # make 'maps' global to simplify the map function inside roots_to_rs()
    global maps, eq_a
    maps = mk_maps(roots)
    # next, convert all of the roots in the equation to use the r-variables
    eq_a = roots_to_rs(eq)

# Print "equation A" in the form parsed by GNU EMACS's outline mode.
# This function is only used for debugging.

def analyze_eq_a(eq, depth=1, print_depth=2, file=sys.stdout):
    if eq.operator():
       print('*' * depth, eq.operator(), len(eq.operands()), file=file)
       if depth >= print_depth: print(eq, file=file)
       for o in eq.operands():
           analyze_eq_a(o, depth+1, print_depth=print_depth, file=file)


# Create a polynomial ring to hold our expressions.
#
# Sage does this using Singular, which stores polynomials internally in standard
# form (i.e, fully expanded).  Singular is the default, while FLINT is available
# as an option, which I tend to use because I've worked on the FLINT code and
# found it more accessible than Singular.
#
# The variables are listed from most significant to least significant.  We use lexicographic
# ordering to group terms together conveniently.
#
# I want 'roots' to be first in the ordering, because they're going to be substituted for,
# so making them the most significant variables groups like 'roots' terms together.
#
# I want the coeff_vars to be last in the ordering, because the system we're going to solve
# will be grouped by coordinates and ODE_vars.
#
# 'encoding' is an option that I've added to the Sage/FLINT implementation to describe
# how the polynomial terms will be written out to disk.  dexlex64(N) encodes N variables
# using 64-bit deglex encoding (see M. Gastineau, Storage of Multivariate Polynomials,
# Advanced School on Specific Algebraic Manipulators, 2007); sint64 encodes the coefficient
# as a signed 64-bit integer, so this encoding encodes each polynomial term using
# three 64-bit words.  If things don't fit, it throws an exception.

def create_polynomial_rings(alg_exts):
    global convertRing,idealRing,reduceRing,RQQ,RZZflint,R32003,convertField,num_rvars,num_cvars
    # we need to add gamma to this to make ansatz 11 (algebraic extension) work
    roots_names = list(map(varName, roots))
    alg_exts_names = [p[0] for p in alg_exts]
    num_rvars = len(alg_exts_names) + len(roots_names) + len(ODE_vars) + len(coordinates)
    num_cvars = len(coeff_vars)
    # encoding isn't used except for writing FLINT polynomials to disk with my custom code
    encoding = 'deglex64({}),deglex64({}),sint64'.format(num_rvars, num_cvars)

    # the ordering here is intended to make reduction mod alg_exts and roots easy
    Rsingular = PolynomialRing(QQ, names=tuple(flatten((alg_exts_names, roots_names, ODE_vars, coordinates, coeff_vars))),
                         order=f'lex({len(alg_exts) + len(roots_names)}), degrevlex({len(ODE_vars) + len(coordinates) + len(coeff_vars)})')

    # used with my custom option to set disk encoding
    #R = PolynomialRing(ZZ, names=tuple(flatten((alg_exts_names, roots_names, ODE_vars, coordinates, coeff_vars))),
    #                   implementation="FLINT", order='lex', encoding=encoding)
    try:
        Rflint = PolynomialRing(ZZ, names=tuple(flatten((alg_exts_names, roots_names, ODE_vars, coordinates, coeff_vars))),
                                implementation="FLINT", order='lex')
    except Exception as ex:
        print(ex)
        print('multivariate FLINT rings unavailable')
        Rflint = None

    # not only might FLINT be unavailable, it doesn't implement Groebner bases, so can't be used for reduction

    if Rflint:
        print('Using FLINT rings for convertion')
        convertRing = Rflint
    else:
        print('Using Singular rings for convertion')
        convertRing = Rsingular

    print('Using Singular rings for reduction ideal')
    idealRing = Rsingular

    #if len(roots) > 0 or len(alg_exts) > 0:
    if False:
        print('Using Singular rings for reduction')
        reduceRing = Rsingular

        # This doesn't work - Singular interface doesn't support splitting variables with the coeff field like this
        # (according to the first few lines of multi_polynomial_libsingular.pyx)
        # I'm not sure about Singular proper.  It has some kind of support for "transcendental extension of Q"
        #Rsingular1 = PolynomialRing(QQ, names=tuple(flatten((ODE_vars, coordinates, coeff_vars))))
        #Rsingular2 = PolynomialRing(FractionField(Rsingular1), names=tuple(flatten((alg_exts_names, roots_names))), order='lex')
    else:
        print('Using convertion ring for reduction')
        reduceRing = convertRing

    convertField = Frac(convertRing)

    # These are the rings used for the system of equations in the coefficients
    RQQ = PolynomialRing(QQ, names=coeff_vars)
    if Rflint:
        RZZflint = PolynomialRing(ZZ, names=coeff_vars, implementation='FLINT')
    R32003 = PolynomialRing(GF(32003), names=coeff_vars)

# we need to add gamma to this to make ansatz 11 (algebraic extension) work
def mk_ideal(R, roots, alg_exts):
    "Given a list or tuple of roots, return a ideal of ring R that reduces the global variable names of those roots"
    global reductionIdeal
    # We expect a tuple of pow's in the Symbolic Ring, so we can easily construct the minimal polynomials
    #
    # We can also take a pair of (varName, minpoly) where varName is a var in the Symbolic Ring
    # and minpoly is a polynomial in the Symbolic Ring that can be converted to R
    ideal_generators = []
    for v in roots:
        assert v.operator() is operator.pow
        Rname = R(varName(v))
        Rexpr = R(v.operands()[0])
        power = int(1/v.operands()[1])
        ideal_generators.append(Rname^power - Rexpr)
    for v,e,postsub in alg_exts:
        assert e in SR
        ideal_generators.append(R(roots_to_rs(e).subs(postsub)))
    reductionIdeal = ideal(ideal_generators)

def convert_eq_a():
    global eq_a_convertField
    # If we write this as 'eq_a_convertField = convertField(eq_a)', Sage will attempt to construct eq_a_convertField by calling
    # eq_a.numerator() and eq_a.denominator(), which will perform lots of rational function
    # math in the Symbolic Ring, which is very slow and memory intensive.  Calling it
    # like 'eq_a.polynomial(ring=convertField)' recurses through the expression tree and builds the
    # expression from the bottom up using polynomial ring operations, which are much more efficient.
    #
    # This trick (currently) only works on my development Sage, so try it and fall back on the slower way.
    try:
        eq_a_convertField = eq_a.polynomial(ring=convertField)
    except:
        print('WARNING: converting eq_a using the Symbolic Ring (this is slow)')
        eq_a_convertField = convertField(eq_a)
    print('eq_a_convertField numerator:', eq_a_convertField.numerator().number_of_terms(), 'terms')

def convertRing_to_reduceRing(element):
    # this doesn't work with my current development sage:
    #   eq_a_reduceRing_n = reduceRing(eq_a_convertField.numerator()).mod(I)
    #   eq_a_reduceRing_d = reduceRing(eq_a_convertField.denominator()).mod(I)
    # I tried converting to a string, but that hits "RecursionError: maximum recursion depth exceeded during compilation"
    #   eq_a_reduceRing_n = reduceRing(str(eq_a_convertField.numerator())).mod(I)
    #   eq_a_reduceRing_d = reduceRing(str(eq_a_convertField.denominator())).mod(I)
    # go this way instead: (works on a simple reduceRing)
    if convertRing != reduceRing:
        return reduceRing(element.dict())
    else:
        return element
    # if reduceRing is a ring over a field with convertRing variables split between the two, we need something else
    # don't bother with this code, as Singular can't support splitting variables between the ring and the coeff field
    #
    #baseRing = reduceRing.base_ring()
    #rest_term_sub = {convertRing(v):1 for v in reduceRing.variable_names()}
    #result = reduceRing(0)
    #for coeff, monomial in element:
    #    coeff_term = monomial.subs(rest_term_sub)
    #    ring_term = reduceRing(monomial / coeff_term)
    #    result += coeff * baseRing(coeff_term) * ring_term
    #return result

def reduce_mod_ideal(element, I=None):
    if I:
        # This way does the reduction in FLINT:
        # (it doesn't work in Singular, the % in Sage's Singular code is Singular's "division", which is not reduction (I'm not sure what it is)
        if 'multi_polynomial_flint' in dir(sage.rings.polynomial) \
           and type(reduceRing) == sage.rings.polynomial.multi_polynomial_flint.MPolynomialRing_flint:
            for p in I.groebner_basis():
                element %= convertRing(str(p))
            return convertRing_to_reduceRing(element)
        # This is slower if convertRing is FLINT and reduceRing is Singular; it does the reduction in Singular:
        if type(reduceRing) == sage.rings.polynomial.multi_polynomial_libsingular.MPolynomialRing_libsingular:
            return convertRing_to_reduceRing(element).mod(I)
        raise "No reduction algorithm defined for reduceRing"
    else:
        return convertRing_to_reduceRing(element)

def reduce_numerator(I=None):
    global eq_a_reduceRing_n
    eq_a_reduceRing_n = reduce_mod_ideal(eq_a_convertField.numerator(), I)
    print('eq_a_reduceRing_n:', eq_a_reduceRing_n.number_of_terms(), 'terms')

def reduce_denominator(I=None):
    global eq_a_reduceRing_d
    eq_a_reduceRing_d = reduce_mod_ideal(eq_a_convertField.denominator(), I)
    print('eq_a_convertField: denominator', eq_a_reduceRing_d.number_of_terms(), 'terms')

import time

def timefunc(func, *args, **kwargs):
    start_time = time.perf_counter()
    retval = func(*args, **kwargs)
    end_time = time.perf_counter()
    print('{:30} {:10.2f} sec'.format(func.__name__, end_time - start_time))
    return retval

# Now expand out powers, and collect like x,y,z's terms together to
# get a system of polynomials
#
# This is a slow step, so I've tried several different ways to do it.

# Look for solutions using an approximate numerical technique

last_time = 0

# We're going from reduceRing to whatever ring is specified, or reduceRing (if not specified)

def build_system_of_equations(ring=None):
    global system_of_like_terms
    system_of_like_terms = dict()
    # for speed, build this tuple here instead of letting the subs method do it in monomial.subs
    # if my custom __evaluate function is available, use it, it's yet faster
    if '__evaluate' in dir(eq_a_reduceRing_n):
        FLINT_evaluate = tuple((n,1) for n in range(reduceRing.ngens()) if reduceRing.gen(n) in coeff_vars)
        print('Using FLINT __evaluate method')
    else:
        FLINT_evaluate = None
        non_coeff_sub = tuple(1 if reduceRing.gen(n) in coeff_vars else reduceRing.gen(n) for n in range(reduceRing.ngens()))
    pb = ProgressBar(label='build_system_of_equations ', expected_size=eq_a_reduceRing_n.number_of_terms())
    # this loop works on Singular or FLINT elements, but not other things like rings with variables in their coeff field
    for i, (coeff, monomial) in enumerate(eq_a_reduceRing_n):
        if i%100 == 99:
            pb.show(i+1)
        if FLINT_evaluate:
            non_coeff_part = monomial.__evaluate(FLINT_evaluate)
        else:
            non_coeff_part = monomial(non_coeff_sub)
        if ring:
            coeff_part = ring(monomial / non_coeff_part)
        else:
            # this cast needs to be here because otherwise the division (even though it's exact) takes us to the fraction field
            coeff_part = reduceRing(monomial / non_coeff_part)
        if (non_coeff_part) in system_of_like_terms:
            system_of_like_terms[non_coeff_part] += coeff * coeff_part
        else:
            system_of_like_terms[non_coeff_part] = coeff * coeff_part
    pb.show(i+1)
    pb.done()
    return tuple(set(system_of_like_terms.values()))

def create_eqns_RQQ():
    global eqns_RQQ, jac_eqns_RQQ
    eqns_RQQ = timefunc(build_system_of_equations, RQQ)

def create_eqns_R32003():
    global eqns_R32003
    eqns_R32003 = tuple(map(lambda arg: arg.map_coefficients(GF(32003), GF(32003)), eqns_RQQ))

def init():
    global reductionIdeal
    # convert_eq_a is the first really time consuming step
    timefunc(convert_eq_a)
    if len(roots) > 0 or len(alg_exts) > 0:
        timefunc(mk_ideal, idealRing, roots, alg_exts)
    else:
        reductionIdeal = None
    timefunc(reduce_numerator, reductionIdeal)
    # We don't use the denominator for anything, currently
    timefunc(reduce_denominator, reductionIdeal)
    timefunc(create_eqns_RQQ)
    timefunc(create_eqns_R32003)

# Factor all of the polynomials in the system of equations and build a set of systems,
# all with irreducible polynomials, that generates the same variety.  From each factored
# set that arises from a polynomial in the original system, we want one factor.
#
# Currently works, but builds way more systems that are really needed.  871 on hydrogen-5,
# when we know we'll only get 5 irreducible varieties.

# code to write and read data in the bitset format used by the build_systems program,
# which is a C++ version of build_systems() below, optimized for speed

from sage.data_structures.bitset import FrozenBitset

def print_build_systems(file=sys.stdout):
    for l in sorted(eqns_RQQ_factors, key=lambda x:len(x)):
        print(FrozenBitset(tuple(all_factors.index(f) for f in l), capacity=len(all_factors)), file=file)

def load_build_systems_output(fn):
    with open(fn) as f:
        s = f.read()
        # The sort can be really slow, though I want it there to verify that systems is the same as created
        #    using the Python code below (the call to add_system() in build_systems() sorts working_ideal first)
        # I also changed the set to a tuple because I want to index it, so I can process one ideal at a time,
        #    and I want it in the same order that it came in from the 'cout' file
        #return set(tuple(sorted(tuple(all_factors[i] for i in FrozenBitset(bs)))) for bs in s.split())
        return tuple(tuple(all_factors[i] for i in FrozenBitset(bs)) for bs in s.split())

# consolidated version of the above subroutines that takes a tuple of equations (generators of an ideal)
# and returns a tuple of tuples of equations, a factorization of the input ideal.

def dropZeros(eqns):
    return tuple(e for e in eqns if e != 0)

def normalize(eqns):
    return tuple(e/e.lc() for e in eqns)

# parallelized Singular polynomial factorization

import concurrent.futures

def factor_eqn(eqn):
    return eqn.factor()

def parallel_factor_eqns(eqns):
    with concurrent.futures.ProcessPoolExecutor(max_workers=12) as executor:
        # "factor" itself is cached; we can't use a functools._lru_cache_wrapper here, so use the underlying sage.arith.misc.factor
        # actually, don't do this - this is some kind of generic factorization
        # futures = [executor.submit(sage.arith.misc.factor, eqn) for eqn in eqns]
        futures = [executor.submit(factor_eqn, eqn) for eqn in eqns]
        pb = ProgressBar(label='factor equations', expected_size=len(eqns))
        num_completed = 0
        while num_completed < len(eqns):
            concurrent.futures.wait(futures, timeout=10)
            num_completed = tuple(future.done() for future in futures).count(True)
            pb.show(num_completed)
    pb.done()
    print()
    return tuple(tuple(f for f,m in future.result()) for future in futures)

def optimized_build_systems(eqns, parallel=True):
    if not parallel:
        eqns_factors = tuple(tuple(f for f,m in factor(eqn)) for eqn in eqns)
        num_threads = 1
    else:
        eqns_factors = parallel_factor_eqns(eqns)
        num_threads = 12
    all_factors = tuple(set(f for l in eqns_factors for f in l))
    with subprocess.Popen(['./build_systems', str(num_threads)], stdin=subprocess.PIPE, stdout=subprocess.PIPE) as proc:
        for l in sorted(eqns_factors, key=lambda x:len(x)):
            proc.stdin.write(str(FrozenBitset(tuple(all_factors.index(f) for f in l), capacity=len(all_factors))).encode())
            proc.stdin.write(b'\n')
        proc.stdin.close()
        return tuple(tuple(all_factors[i] for i in FrozenBitset(bs.decode().strip())) for bs in proc.stdout)

def is_irreducible(eq):
    factors = factor(eq)
    return len(factors) == 1 and not any(m > 1 for f,m in factors)

debug_build_systems = False

# Setup caching for factorization and degree testing, which together speed hydrogen-5 from 90 sec to 15 sec

if type(factor) is not functools._lru_cache_wrapper:
    factor = functools.lru_cache(maxsize=None)(factor)

@functools.lru_cache(maxsize=None)
def is_linear_in_var(poly, v):
    return poly.degree(v) == 1 and poly.coefficient(v).is_constant()

# Algorithm:
#   - run through the system of equations from beginning to end
#   - we're tracking a system of equations, initially empty
#   - for each equation, either its already satisfied, or we need to change something to satisfy it
#   - to check if the equation is satisfied, look first to see if any of its factors are in the system of equations
#     (if so it's satisfied)
#   - if the equation is satisfied, skip to the next one
#   - if the equation is not satisfied, call subroutine one; it returns a list of tuples
#   - each tuple is a system of equations and the number of the equation we're working on
#   - for each tuple in the list, continue the main loop starting with the next equation
#   - when we get through the entire system, add the system of equations to the output
#   - pop the last tuple on the list and go back to the top of this loop

def add_system(systems, newsys):
    #print("adding system")
    systems_to_remove = []
    for sys in systems:
        # if an existing sys is a strict subset of newsys, we don't do anything
        if len(sys) < len(newsys) and all(p in newsys for p in sys):
            return
        if len(newsys) < len(sys) and all(p in sys for p in newsys):
            systems_to_remove.append(sys)
    for sys in systems_to_remove:
        systems.remove(sys)
    systems.add(newsys)

def build_systems(eqns):
    eqns_factors = tuple(tuple(f for f,m in factor(eqn)) for eqn in eqns)
    all_factors = tuple(set(f for l in eqns_factors for f in l))
    systems = set()
    working_ideal = set()
    tracking_info = list()
    last_i = -1
    start_point = float(0.0)
    end_point = float(100.0)
    total_progress = float(0.0)
    #pb = ProgressBar(label='build_systems ', expected_size=int(end_point))
    while True:
        # put this here in case we've just popped from tracking_info and last_i = len(eqns)-1
        # In that case, we don't have anything to do in the next for loop (all of the equations are accounted for),
        #    but we need to make sure that the "i == len(eqns) - 1" test triggers, and the for loop won't
        #    change i at all if the range is empty
        i = last_i
        for i in range(last_i+1, len(eqns)):
            # if any polynomial in the working ideal is a factor of this equation, skip the equation, as it's already satisfied
            if not working_ideal.isdisjoint(eqns_factors[i]):
                continue
            tracking_info.extend(subroutine_one(eqns_factors[i], working_ideal, i, start_point, end_point))
            #print(tracking_info)
            if debug_build_systems:
                for r,a,b in tracking_info:
                    for eq2 in r:
                        assert is_irreducible(eq2), "loop 1"
            if i == len(eqns) - 1:
                # force it to pop from tracking_info
                i = 0
            break
        #print('i', i)
        # working_ideal might have factors in it, if we broke out of the loop, but we're about to discard it in that case
        if i == len(eqns) - 1:
            add_system(systems, tuple(sorted(tuple(working_ideal))))
            #pb.show(int(end_point))
            #total_progress += end_point - start_point
            #print('progress', total_progress, 'len(systems)', len(systems))
            if debug_build_systems:
                for eq in working_ideal:
                    try:
                        assert is_irreducible(eq), "point 2"
                    except AssertionError:
                        print(old_working_ideal)
                        print(working_ideal)
                        raise
        try:
            working_ideal, last_i, start_point, end_point = tracking_info.pop()
            if debug_build_systems:
                for eq in working_ideal:
                    assert is_irreducible(eq), "point 3"
        except IndexError:
            return systems

# Call subroutine one:
#   - input is a list, a set of equations (to be satisfied) and an equation number for labeling purposes
#   - the first input is a list of factors, one of which has to be added to the set
#   - loop over the factors and add each one to the set, returning the union of all the resulting sets

def subroutine_one(factors, equations, equation_number, start_point, end_point):
    #print('subroutine_one', equations, equation_number)
    if debug_build_systems:
        assert type(equations) == set
    result = []
    for i,f in enumerate(factors):
        newset = equations.copy()
        newset.add(f)
        new_start_point = start_point + (len(factors) - i - 1)*(end_point - start_point)/len(factors)
        new_end_point = start_point + (len(factors) - i)*(end_point - start_point)/len(factors)
        #print('start/end_point', start_point, end_point)
        #print('new start/end_point', new_start_point, new_end_point)
        result.append((newset, equation_number, new_start_point, new_end_point))
    return result

# Once we've built all of the systems, then we do this:
#
# consolidate_ideals(reduce(lambda a,b: a.union(b), [set(ideal(s).minimal_associated_primes()) for s in systems]))
#
# i.e, compute the minimum associated prime ideals of each system, union the results all together,
# and discard any ideals which are a subset of another ideal
#
# For hydrogen-5, this method produces the same set of five ideals that were generated by computing
# the radical and primary decomposition directly on the original system.  My hope is that this
# method will be usable for helium-16.6, where the direct approach runs out of memory, though
# it is slower for hydrogen-5.

# consolidate_ideals(list_of_ideals)
#
# For ideals, A < B if A is a subset of B
#
# We seek to represent our original ideal as an intersection of prime ideals.
# If any ideal is a strict subset of another in the set, we
# can discard the larger of the two without affecting the intersection.

def consolidate_ideals(list_of_ideals):
    consolidated_ideals = []
    for ideal in list_of_ideals:
        if any(I < ideal for I in consolidated_ideals):
            continue
        consolidated_ideals = [I for I in consolidated_ideals if not ideal < I]
        consolidated_ideals.append(ideal)
    return consolidated_ideals

#
# Helper functions for the "Pseudo-Solution of Hydrogen" paper
#

def latex_array(eqns):
    print("\\begin{array}{r}")
    for eqn in eqns:
        print(latex(eqn) + "\\\\")
    print("\\end{array}\n")

# The "simplifyIdeal" procedure in Singular's primdec.lib (primary decomposition library) checks
# for equations with simple variable substitutions, but doesn't get all linear relations.
# It's used as a preprocessing step before starting into something like the GTZ algorithm
# to compute a primary decomposition.  Let's do that step here, but also check for the
# more complicated linear relations.
#
# It finds things like v+p()=0, where p() doesn't involve v, but I also want to get
# q()v+p()=0, which can be split into two systems, one where q and p are both zero,
# and the other where v=-p/q.

def simplifyIdeal(I):
    # I should be a list or a tuple, not an ideal
    # returns a pair: a list of equations and a list of substitutions
    # The substitutions are equations with a simple linear term that were eliminated from the first list of equations
    try:
        from sage.libs.singular.function_factory import ff
        singularSimplifyIdeal = ff.primdec__lib.simplifyIdealBWB
        return singularSimplifyIdeal(ideal(I))
    except NameError:
        print("Singular simplifyIdealBWB not available; falling back on slow Python version")
    simplifications = []
    for v in I[0].parent().gens():
        for p in I:
            if p == 0:
                pass
            elif p/p.lc() == v:
                #print(v, "=", 0)
                I = tuple(map(lambda p: p.subs({v: 0}), I))
                simplifications.append(v)
            elif p.degree(v) == 1:
                q,r = p.quo_rem(v)
                if r == 0:
                    # We should pick this up case with another run through optimized_build_systems
                    # print("reducible polynomial detected")
                    pass
                elif q.is_constant() and r.number_of_terms() == 1:
                    # polynomial is qv+r; qv+r=0; replace v with -r/q
                    #print(v, "=", -r/q)
                    #start_time = time.time()
                    I = tuple(map(lambda p: p.subs({v: -r/q}), I))
                    #execution_time = time.time() - start_time
                    #print(f'subs done in {execution_time} seconds')
                    simplifications.append(q*v+r)
                    break
    return I,tuple(simplifications)

def simplifyIdeal2(I):
    # I should be a list or a tuple, not an ideal
    for v in I[0].parent().gens():
        q_candidate = None
        r_candidate = None
        for p in I:
            if p.degree(v) == 1:
                q,r = p.quo_rem(v)
                if r == 0:
                    print("reducible polynomial detected")
                elif not q_candidate or q.number_of_terms() < q_candidate.number_of_terms() or \
                        (q.number_of_terms() == q_candidate.number_of_terms() and r.number_of_terms() < r_candidate.number_of_terms()):
                    q_candidate = q
                    r_candidate = r
        if q_candidate:
            # v=qv+r; replace v with -r/q
            print(v, "=", -r_candidate/q_candidate)
            start_time = time.time()
            I = tuple(map(lambda p: p.subs({v: -r_candidate/q_candidate}).numerator(), I))
            execution_time = time.time() - start_time
            print(f'subs done in {execution_time} seconds')
    return I

# We use simple simplifications (factoring polynomials and substituting for linear variables) to split a big
# system of polynomial equations into subsystems, each of which are then pickled and stored into a SQL
# database.  Then we'll come back and simplify each subsystem using Singular's GTZ algorithm.
#
# Each system is separated into two subsets - complex polynomials (no linear terms) and simple polynomials (a linear term in each).
# This is done to simplify the GTZ calculations, which only need to be done on the complex set, as
# once you know the solutions to the complex set, the solutions to the linear set can be easily calculated.

sql_schema='''
CREATE TYPE status AS ENUM ('queued', 'running', 'finished', 'interrupted', 'failed');

CREATE TABLE systems (
      identifier INTEGER GENERATED ALWAYS AS IDENTITY,
      system BYTEA,               -- a pickle of a tuple pair of tuples of polynomials; the first complex, the second simple
      simplified_system BYTEA,    -- initially NULL; ultimately a pickle of a tuple of tuples of simplified systems
      current_status status,
      degree INTEGER,             -- the maximum degree of the polynomials in the system
      cpu_time INTERVAL,
      memory_utilization BIGINT,
      pid INTEGER,
      num INTEGER                 -- the number of identical systems that have been found
);

CREATE UNIQUE INDEX ON systems(md5(system));

CREATE TABLE stage1 (
      identifier INTEGER GENERATED ALWAYS AS IDENTITY,
      system BYTEA,               -- a pickle of a tuple of polynomials
      current_status status,
      cpu_time INTERVAL,          -- I'm actually using this for wall time
      memory_utilization BIGINT,
      node VARCHAR,
      pid INTEGER
);

CREATE TABLE stage2 (
      identifier INTEGER GENERATED ALWAYS AS IDENTITY,
      origin INTEGER,
      system BYTEA,               -- a pickle of a tuple pair of tuples of polynomials; the first complex, the second simple
      current_status status,
      cpu_time INTERVAL,          -- I'm actually using this for wall time
      memory_utilization BIGINT,
      node VARCHAR,
      pid INTEGER
);

CREATE TABLE tracking (
      origin INTEGER,
      destination INTEGER,
      count INTEGER
);

CREATE UNIQUE INDEX ON tracking(origin, destination);

CREATE TABLE globals (            -- this table contains the pickled rings, to keep down the size of the pickled polynomials
      identifier INTEGER GENERATED ALWAYS AS IDENTITY,
      pickle BYTEA
);

-- Making "pickle" unique causes the resulting index to exceed a PostgreSQL limit, so we make the md5 hash unique instead.

CREATE UNIQUE INDEX ON globals(md5(pickle));
'''

def delete_database():
    with conn.cursor() as cursor:
        cursor.execute("DROP OWNED BY current_user")
    conn.commit()

def create_database():
    with conn.cursor() as cursor:
        cursor.execute(sql_schema)
    conn.commit()

# To keep the size of our pickled objects down, we don't pickle the ring that the polynomials come from.

persistent_data = {}
persistent_data_inverse = {}

def save_global(obj):
    p = persistent_pickle(obj)
    with conn.cursor() as cursor:
        cursor.execute("INSERT INTO globals (pickle) VALUES (%s) ON CONFLICT DO NOTHING", (p,))
    conn.commit()
    with conn.cursor() as cursor:
        cursor.execute("SELECT identifier FROM globals WHERE pickle = %s", (p,))
        id = cursor.fetchone()[0]
        persistent_data[str(id)] = obj
        persistent_data_inverse[obj] = str(id)

def load_globals():
    with conn.cursor() as cursor:
        cursor.execute("SELECT identifier, pickle FROM globals")
        for id, p in cursor:
            obj = pickle.loads(p)
            persistent_data[str(id)] = obj
            persistent_data_inverse[obj] = str(id)

def persistent_id(obj):
    # It's hard to tell if an arbitrary Python object is hashable
    #    See https://stackoverflow.com/a/3460725/1493790
    # The stackoverflow suggestion (try/except) is quite slow
    if isinstance(obj, sage.rings.ring.Ring) or isinstance(obj, sage.rings.polynomial.multi_polynomial.MPolynomial):
        if obj in persistent_data_inverse:
            return persistent_data_inverse[obj]
    return None

# This is pretty much how the dumps code works, except that it tries first to use an optimized version from _pickle
def pickleWithoutRing(val):
    src = io.BytesIO()
    p = pickle.Pickler(src)
    p.persistent_id = persistent_id
    p.dump(val)
    if val[0] == tuple():
        deg = 1
    else:
        deg = max(p.degree() for p in val[0])
    return (src.getvalue(), int(deg))

def persistent_pickle(val):
    src = io.BytesIO()
    p = pickle.Pickler(src)
    p.persistent_id = persistent_id
    p.dump(val)
    return src.getvalue()

def persistent_load(id):
    if id not in persistent_data:
        with conn.cursor() as cursor:
            cursor.execute("SELECT pickle FROM globals WHERE identifier = %s", (int(id),))
            if cursor.rowcount == 0:
                raise pickle.UnpicklingError("Invalid persistent id")
            else:
                obj = unpickle(cursor.fetchone()[0])
                persistent_data[id] = obj
                persistent_data_inverse[obj] = id
    return persistent_data[id]

def unpickle(p):
    dst = io.BytesIO(p)
    up = pickle.Unpickler(dst)
    up.persistent_load = persistent_load
    return up.load()

# Forking after simplifyIdeal4_list_of_systems has been created and passing "i" (instead of passing one of the systems)
# is done to avoid serialization delay in the parallel code.  For the same reason, we put the results into a SQL
# database here instead of returning them across the fork and then putting them in the database.  Returning the
# values this way also drops them from RAM, which keeps the memory footprint under control, rather than storing
# everything in RAM until the futures in simplifyIdeal4 complete.

def simplifyIdeal5(i, simplifications, depth):
    global conn
    if conn:
        conn.close()
        conn = psycopg2.connect(**postgres_connection_parameters)
    retval = simplifyIdeal4(simplifyIdeal4_list_of_systems[i], simplifications, depth)
    if conn:
        retval_unique = set(retval)
        retval_unique_pickles_with_degrees_and_counts = tuple(pickleWithoutRing(rv) + (retval.count(rv),) for rv in retval_unique)
        retval_hashes = {str(uuid.UUID(bytes=hashlib.md5(p[0]).digest())):p for p in retval_unique_pickles_with_degrees_and_counts}
        with conn.cursor() as cursor:
            for h,p in retval_hashes.items():
                cursor.execute("INSERT INTO systems (md5, system, degree, num, current_status) VALUES (%s, %s, %s, 0, 'queued') ON CONFLICT DO NOTHING",
                               (h, p[0], p[1]))
                cursor.execute("UPDATE systems SET num = num + %s WHERE md5 = %s", (p[2], h))
        conn.commit()
        return []
    else:
        return retval

def load_systems():
    conn2 = psycopg2.connect(**postgres_connection_parameters)
    retval = []
    with conn2.cursor() as cursor:
        cursor.execute("SELECT system FROM systems;")
        for pickled_system in cursor:
            dst = io.BytesIO(pickled_system[0])
            up = pickle.Unpickler(dst)
            up.persistent_load = persistent_load
            retval.append(up.load())
    conn2.close()
    return retval

def done_callback(future):
    if future.exception():
        print(*traceback.format_exception(future.exception()))

def simplifyIdeal4(eqns, simplifications=tuple(), depth=1):
    #print('simplifyIdeal4:', eqns, simplifications)
    eqns,s = simplifyIdeal(eqns)
    #print('simplifyIdeal:', eqns,s)
    #simplifications.extend(normalize(s))
    simplifications = simplifications + normalize(s)
    eqns = normalize(dropZeros(eqns))
    if len(eqns) == 0:
        return [(tuple(), simplifications)]
    if any(eqn == 1 for eqn in eqns):
        return []
    list_of_systems = optimized_build_systems(eqns, parallel=(depth == 1))
    if len(list_of_systems) == 1:
        return [(eqns, simplifications)]
    else:
        #print('recursing on', len(list_of_systems), 'systems; depth', depth)
        if depth == 1:
            num_of_systems = len(list_of_systems)
            pb = ProgressBar(label='simplify equations', expected_size=num_of_systems)
            # Use a global variable to avoid serialization delay in relaying the polynomials to worker subprocesses
            global simplifyIdeal4_list_of_systems
            simplifyIdeal4_list_of_systems = list_of_systems
            with concurrent.futures.ProcessPoolExecutor(max_workers=12) as executor:
                futures = [executor.submit(simplifyIdeal5, i, simplifications, depth+1) for i in range(num_of_systems)]
                for future in futures:
                    future.add_done_callback(done_callback)
                num_completed = 0
                while num_completed < num_of_systems:
                    concurrent.futures.wait(futures, timeout=1)
                    num_completed = tuple(future.done() for future in futures).count(True)
                    pb.show(num_completed)
            pb.done()
            return [l for future in futures for l in future.result()]
        else:
            return [l for sys in list_of_systems for l in simplifyIdeal4(sys, simplifications, depth+1)]

def process_pool_initializer():
    # futures can't share the original SQL connection, so create a new one
    # We DON'T want to close the existing connection, since it's still being used by the parent process
    global conn
    conn = psycopg2.connect(**postgres_connection_parameters)

def dump_bitset_to_SQL(origin, i):
    global bitsets
    global all_factors
    global simplifications
    t = tuple(all_factors[j] for j in bitsets[i])
    system = persistent_pickle((t,simplifications))
    with conn.cursor() as cursor:
        cursor.execute("INSERT INTO stage2 (system, origin, current_status) VALUES (%s, %s, 'queued')", (system, origin))
    conn.commit()

def stage2(system, origin):
    print('simplifyIdeal')
    eqns,s = simplifyIdeal(system)
    # simplifications = simplifications + normalize(s)
    global simplifications
    simplifications = normalize(s)
    save_global(simplifications)
    eqns = normalize(dropZeros(eqns))
    if len(eqns) == 0:
        with conn.cursor() as cursor:
            p = persistent_pickle(simplifications)
            h = str(uuid.UUID(bytes=hashlib.md5(p).digest()))
            cursor.execute("INSERT INTO systems (md5, system, degree, num, current_status) VALUES (%s, %s, 1, 0, 'queued') ON CONFLICT DO NOTHING",
                           (h, p))
            cursor.execute("UPDATE systems SET num = num + %s WHERE md5 = %s", (p[2], h))
        conn.commit()
    if any(eqn == 1 for eqn in eqns):
        # the system is inconsistent and needs no further processing
        return
    # list_of_systems = optimized_build_systems(eqns, parallel=True)
    eqns_factors = parallel_factor_eqns(eqns)
    num_threads = 12
    global all_factors
    all_factors = tuple(set(f for l in eqns_factors for f in l))
    pb = ProgressBar(label='saving factors as globals', expected_size=len(all_factors))
    for i,f in enumerate(all_factors):
        save_global(f)
        pb.show(i)
    pb.done()
    print()
    with subprocess.Popen(['./build_systems', str(num_threads)], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) as proc:
        for l in sorted(eqns_factors, key=lambda x:len(x)):
            proc.stdin.write(str(FrozenBitset(tuple(all_factors.index(f) for f in l), capacity=len(all_factors))).encode())
            proc.stdin.write(b'\n')
        proc.stdin.close()
        global bitsets
        bitsets = tuple(FrozenBitset(bs.decode().strip()) for bs in proc.stdout)
    pb = ProgressBar(label='dump to SQL', expected_size=len(bitsets))
    with concurrent.futures.ProcessPoolExecutor(max_workers=12, initializer=process_pool_initializer) as executor:
        futures = [executor.submit(dump_bitset_to_SQL, origin, i) for i in range(len(bitsets))]
        for future in futures:
            future.add_done_callback(done_callback)
        num_completed = 0
        while num_completed < len(bitsets):
            concurrent.futures.wait(futures, timeout=1)
            num_completed = tuple(future.done() for future in futures).count(True)
            pb.show(num_completed)
    pb.done()
    print()
    for future in futures:
        future.result()

def SQL_stage2():
    with conn.cursor() as cursor:
        while True:
            cursor.execute("""UPDATE stage1
                              SET current_status = 'running', pid = %s, node = %s
                              WHERE identifier = (
                                  SELECT identifier
                                  FROM stage1
                                  WHERE current_status = 'queued'
                                  ORDER BY identifier
                                  LIMIT 1
                                  )
                              RETURNING system, identifier""", (os.getpid(), os.uname()[1]) )
            conn.commit()
            if cursor.rowcount == 0:
                break
            pickled_system, identifier = cursor.fetchone()
            start_time = time.time()
            print('Unpickling stage 1 system', identifier)
            system = unpickle(pickled_system)

            stage2(system, identifier)

            memory_utilization = psutil.Process(os.getpid()).memory_info().rss
            cpu_time = datetime.timedelta(seconds = time.time() - start_time)
            cursor.execute("""UPDATE stage1
                              SET current_status = 'finished',
                                  cpu_time = %s,
                                  memory_utilization = %s
                              WHERE system = %s""", (cpu_time, memory_utilization, pickled_system))
            conn.commit()

            # keep our memory down by clearing our cached polynomials
            persistent_data.clear()
            persistent_data_inverse.clear()


def insert_into_systems(system, simplifications, origin):
    for eqn in system:
        save_global(eqn)
    for eqn in simplifications:
        save_global(eqn)
    p = persistent_pickle((system, simplifications))
    if len(system) == 0:
        deg = 1
    else:
        deg = max(p.degree() for p in system)
    with conn.cursor() as cursor:
        #cursor.execute("INSERT INTO systems (system, degree, num, current_status) VALUES (%s, %s, 0, 'queued') ON CONFLICT DO NOTHING",
        #               (p, deg))
        #cursor.execute("SELECT identifier FROM systems WHERE system = %s", (p,))
        cursor.execute("""INSERT INTO systems (system, degree, num, current_status) VALUES (%s, %s, 1, 'queued')
                          ON CONFLICT (md5(system)) DO UPDATE SET num = systems.num + 1
                          RETURNING identifier""",
                       (p, int(deg)))
        id = cursor.fetchone()[0]
        cursor.execute("""INSERT INTO tracking (origin, destination, count) VALUES (%s, %s, 1)
                          ON CONFLICT (origin, destination) DO UPDATE SET count = tracking.count + 1""",
                       (origin, id))
    conn.commit()

def stage3(system, simplifications, origin):
    eqns,s = simplifyIdeal(system)
    simplifications = simplifications + normalize(s)
    eqns = normalize(dropZeros(eqns))
    if len(eqns) == 0:
        insert_into_systems(eqns, simplifications, origin)
        return
    if any(eqn == 1 for eqn in eqns):
        # the system is inconsistent and needs no further processing
        return
    list_of_systems = optimized_build_systems(eqns, parallel=False)
    if len(list_of_systems) == 1:
        insert_into_systems(eqns, simplifications, origin)
    else:
        for system in list_of_systems:
            stage3(system, simplifications, origin)


def SQL_stage3_single_thread():
    with conn.cursor() as cursor:
        while True:
            # This post explains the subquery and the use of "FOR UPDATE SKIP LOCKED"
            # https://dba.stackexchange.com/a/69497
            cursor.execute("""UPDATE stage2
                              SET current_status = 'running', pid = %s, node = %s
                              WHERE identifier = (
                                  SELECT identifier
                                  FROM stage2
                                  WHERE current_status = 'queued'
                                  ORDER BY identifier
                                  LIMIT 1
                                  FOR UPDATE SKIP LOCKED
                                  )
                              RETURNING system, identifier""", (os.getpid(), os.uname()[1]) )
            conn.commit()
            if cursor.rowcount == 0:
                break
            pickled_system, identifier = cursor.fetchone()
            try:
                start_time = time.time()
                print('Unpickling stage 2 system', identifier)
                system_pair = unpickle(pickled_system)

                stage3(system_pair[0], system_pair[1], identifier)

                memory_utilization = psutil.Process(os.getpid()).memory_info().rss
                cpu_time = datetime.timedelta(seconds = time.time() - start_time)
                cursor.execute("""UPDATE stage2
                                  SET current_status = 'finished',
                                      cpu_time = %s,
                                      memory_utilization = %s
                                  WHERE system = %s""", (cpu_time, memory_utilization, pickled_system))
                conn.commit()
            except:
                conn.rollback()
                cursor.execute("""UPDATE stage2
                                  SET current_status = 'interrupted'
                                  WHERE identifier = %s""", (identifier,))
                conn.commit()
                raise

            # keep our memory down by clearing our cached polynomials
            persistent_data.clear()
            persistent_data_inverse.clear()

def SQL_stage3(max_workers = 12):
    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers, initializer=process_pool_initializer) as executor:
        futures = [executor.submit(SQL_stage3_single_thread) for _ in range(max_workers)]
        for future in futures:
            future.add_done_callback(done_callback)
        num_completed = 0
        while num_completed < max_workers:
            concurrent.futures.wait(futures, timeout=1)
            num_completed = tuple(future.done() for future in futures).count(True)
    for future in futures:
        future.result()

def SQL_stage1(eqns):
    save_global(eqns[0].parent())
    eqns_factors = parallel_factor_eqns(eqns)
    num_threads = 12
    all_factors = tuple(set(f for l in eqns_factors for f in l))
    for f in all_factors:
        save_global(f)
    with subprocess.Popen(['./build_systems', str(num_threads)], stdin=subprocess.PIPE, stdout=subprocess.PIPE) as proc:
        for l in sorted(eqns_factors, key=lambda x:len(x)):
            proc.stdin.write(str(FrozenBitset(tuple(all_factors.index(f) for f in l), capacity=len(all_factors))).encode())
            proc.stdin.write(b'\n')
        proc.stdin.close()
        with conn.cursor() as cursor:
            for bs in proc.stdout:
                t = tuple(all_factors[i] for i in FrozenBitset(bs.decode().strip()))
                cursor.execute("INSERT INTO stage1 (system, current_status) VALUES (%s, 'queued')", (persistent_pickle(t),))
        conn.commit()

def simplify_one_system():
    with conn.cursor() as cursor:
        cursor.execute("""UPDATE stage1
                          SET current_status = 'running', pid = %s, node = %s
                          WHERE system = (
                              SELECT system
                              FROM stage1
                              WHERE current_status = 'queued'
                              LIMIT 1
                              )
                          RETURNING system""", (os.getpid(), os.uname()[1]) )
        conn.commit()
        if cursor.rowcount != 0:
            pickled_system = cursor.fetchone()[0]
            start_time = time.time()
            system = unpickle(pickled_system)
            simplifyIdeal4(system)
            memory_utilization = psutil.Process(os.getpid()).memory_info().rss
            cpu_time = datetime.timedelta(seconds = time.time() - start_time)
            cursor.execute("""UPDATE stage1
                              SET current_status = 'finished',
                                  cpu_time = %s,
                                  memory_utilization = %s
                              WHERE system = %s""", (cpu_time, memory_utilization, pickled_system))
            conn.commit()

def process_pair(i):
    # The pair is a pair of sets of polynomials.  The first one (might be empty) is relatively complex
    # (all irreducible, no linear terms) while the second one is simpler (all linear terms).  We only need to run
    # the GTZ algorithm on the first one, since once we have a solution to the first system, the solution
    # to the second system is obvious.
    pair = result[i]
    try:
        if len(pair[0]) > 0:
            minimal_primes = ideal(pair[0]).minimal_associated_primes(algorithm=['GTZ', 'gtz', 'noFacstd'])
            return [tuple(I.gens()) + tuple(pair[1]) for I in minimal_primes]
        else:
            return [pair[1]]
    except RuntimeError:
        print('RuntimeError in result', i)
        return []

def process_pairs(start, end, degree=None):
    if degree is None:
        results = [process_pair(i) for i in range(start,end)]
    else:
        results = [process_pair(i) for i in range(start,end) if max(map(lambda p: p.degree(), result[i][0]), default=0) == degree]
    return [i for r in results for i in r]

def process_result(result):
   num_results = len(result)
   retval = []
   pb = ProgressBar(label='GTZ', expected_size=num_results)
   for i in range(num_results):
       retval.append(process_pair(i))
       pb.show(i)
   pb.done()
   return retval

def parallel_process_result(result, degree=None):
    num_results = len(result)
    num_slices = 10000
    retval = []
    pb = ProgressBar(label='GTZ', expected_size=num_slices)
    with concurrent.futures.ProcessPoolExecutor(max_workers=12) as executor:
        futures = [executor.submit(process_pairs, int((num_results*i)/num_slices), int((num_results*(i+1))/num_slices), degree=degree) for i in range(num_slices)]
        num_completed = 0
        while num_completed < num_slices:
            concurrent.futures.wait(futures, timeout=1)
            num_completed = tuple(future.done() for future in futures).count(True)
            pb.show(num_completed)
    pb.done()
    return [l for future in futures for l in future.result()]

def simplifyIdeal6(I):
    # I should be a list or a tuple of polynomials, not an ideal
    # returns a list of equations after substituting zero for any variables that appear alone in the system
    #
    # Maybe we could use the Singular version, but it's return convention is different
    #
    # try:
    #     from sage.libs.singular.function_factory import ff
    #     singularSimplifyIdeal = ff.primdec__lib.simplifyIdealBWB
    #     return singularSimplifyIdeal(ideal(I))
    # except NameError:
    #     print("Singular simplifyIdealBWB not available; falling back on slow Python version")
    simplifications = []
    for v in I[0].parent().gens():
        for p in I:
            if p == 0:
                pass
            elif p/p.lc() == v:
                #print(v, "=", 0)
                I = tuple(map(lambda p: p.subs({v: 0}), I))
                simplifications.append(v)
    return simplifications + [p for p in I if p != 0]

def md5_everything():
    while True:
        with conn.cursor() as cursor:
            with conn.cursor() as cursor2:
                cursor.execute("SELECT DISTINCT system FROM systems WHERE md5 IS null LIMIT 10")
                if cursor.rowcount == 0:
                    break
                for system in cursor:
                    hash = str(uuid.UUID(bytes=hashlib.md5(system[0]).digest()))
                    cursor2.execute("UPDATE systems SET md5 = %s WHERE system = %s;", (hash, system[0]))
        print('one md5 block done')
        conn.commit()

def concurrent_md5_everything():
    # futures can't share the original connection
    conn = psycopg2.connect(**postgres_connection_parameters)
    while True:
        with conn.cursor() as cursor:
            with conn.cursor() as cursor2:
                cursor.execute("SELECT DISTINCT system FROM systems WHERE md5 IS null LIMIT 10")
                if cursor.rowcount == 0:
                    break
                for system in cursor:
                    hash = str(uuid.UUID(bytes=hashlib.md5(system[0]).digest()))
                    cursor2.execute("UPDATE systems SET md5 = %s WHERE system = %s;", (hash, system[0]))
        print('one md5 block done')
        conn.commit()

def md5_test():
    with conn.cursor() as cursor:
        cursor.execute("SELECT md5 FROM systems LIMIT 1;")
        for system in cursor:
            return system[0]

def concurrent_GTZ_everything():
    # futures can't share the original connection
    conn = psycopg2.connect(**postgres_connection_parameters)
    while True:
        with conn.cursor() as cursor:
            cursor.execute("""UPDATE systems
                              SET current_status = 'running', pid = %s
                              WHERE md5 = ( SELECT md5 FROM systems WHERE current_status = 'queued' ORDER BY degree LIMIT 1 )
                              RETURNING md5, system""", (os.getpid(),) )
            conn.commit()
            if cursor.rowcount == 0:
                break
            md5, pickled_system = cursor.fetchone()
            start_time = time.time()
            system, simplifications = unpickle(pickled_system)
            if len(system) == 0:
                subsystems = tuple((simplifyIdeal6(simplifications), ))
            else:
                minimal_primes = ideal(system).minimal_associated_primes(algorithm=['GTZ', 'gtz', 'noFacstd'])
                subsystems = tuple(simplifyIdeal6(mp.gens() + simplifications) for mp in minimal_primes)
            memory_utilization = psutil.Process(os.getpid()).memory_info().rss
            cpu_time = datetime.timedelta(seconds = time.time() - start_time)
            cursor.execute("""UPDATE systems
                              SET simplified_system = %s,
                                  current_status = 'finished',
                                  cpu_time = %s,
                                  memory_utilization = %s
                              WHERE md5 = %s""", (persistent_pickle(subsystems), cpu_time, memory_utilization, md5))
            conn.commit()

def list_systems():
    with conn.cursor() as cursor:
        cursor.execute("SELECT system FROM systems WHERE current_status = 'finished'")
        for sys in cursor:
            print(unpickle(sys[0]))

def list_simplified_systems():
    with conn.cursor() as cursor:
        cursor.execute("SELECT simplified_system FROM systems WHERE current_status = 'finished'")
        for sys in cursor:
            print(unpickle(sys[0]))

def load_simplified_systems():
    retval = []
    with conn.cursor() as cursor:
        cursor.execute("SELECT simplified_system FROM systems WHERE current_status = 'finished'")
        for sys in cursor:
            retval.append(unpickle(sys[0]))
    return retval
